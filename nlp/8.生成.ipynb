{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff223689",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[24717, 649, 3200, 507, 422, 262, 21694, 4991], [3642, 1299, 645, 20868, 837, 691, 2248, 1850, 308, 3775]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#加载编码器\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "#添加pad\n",
    "#tokenizer.add_special_tokens({'pad_token': '<|endoftext|>'})\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#编码试算\n",
    "tokenizer.batch_encode_plus([\n",
    "    'hide new secretions from the parental units',\n",
    "    'contains no wit , only labored gags'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b499b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at datas/imdb/train/cache-1d535447c1465b6c.arrow and datas/imdb/train/cache-e90a494c3d555261.arrow\n",
      "Loading cached shuffled indices for dataset at datas/imdb/train/cache-d0103816d7176d46.arrow\n",
      "Loading cached shuffled indices for dataset at datas/imdb/train/cache-eb5685c86456ecec.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-2a96f14a7578e489.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-067837a2d816bf82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-af81cf006a6a947e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-296d547c05833599.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-d8c36e759992d45e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-0901fa7715bba813.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-0366ef2f735087b2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-c9f0dfc46457adf9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-acd1bb5d6ba45c71_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-acd1bb5d6ba45c71_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-acd1bb5d6ba45c71_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-acd1bb5d6ba45c71_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-dc8b9e8601cc8455_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-dc8b9e8601cc8455_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-dc8b9e8601cc8455_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-dc8b9e8601cc8455_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-9906f3cd542c0fa2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-841d891b93b4bc07.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-618be455982094aa.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-c521da6316862744.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-ed91b24e3add7132.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-cc6fbee431f24db2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-5db45ac2efda8395.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at datas/imdb/train/cache-6e280417b8978311.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 44863\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "\n",
    "#加载数据\n",
    "#dataset = load_dataset('imdb')\n",
    "#dataset.save_to_disk('datas/imdb')\n",
    "dataset = load_from_disk('datas/imdb')\n",
    "\n",
    "#重新切分数据集\n",
    "dataset = concatenate_datasets(\n",
    "    [dataset['train'], dataset['test'], dataset['unsupervised']])\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.01, seed=0)\n",
    "\n",
    "#采样,数据量太大了跑不动\n",
    "dataset['train'] = dataset['train'].shuffle(0).select(range(80000))\n",
    "dataset['test'] = dataset['test'].shuffle(0).select(range(200))\n",
    "\n",
    "\n",
    "#分词\n",
    "def f(data):\n",
    "    #移除<br/>\n",
    "    for i in range(len(data['text'])):\n",
    "        data['text'][i] = data['text'][i].replace('<br /><br />', ' ')\n",
    "\n",
    "    data = tokenizer.batch_encode_plus(data['text'])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "dataset = dataset.map(f,\n",
    "                      batched=True,\n",
    "                      num_proc=4,\n",
    "                      batch_size=1000,\n",
    "                      remove_columns=['text', 'label'])\n",
    "\n",
    "\n",
    "#过滤掉太短的句子\n",
    "def f(data):\n",
    "    return [sum(i) >= 25 for i in data['attention_mask']]\n",
    "\n",
    "\n",
    "dataset = dataset.filter(f, batched=True, num_proc=4, batch_size=1000)\n",
    "\n",
    "\n",
    "#拼合句子到统一的长度\n",
    "def f(data):\n",
    "    block_size = 512\n",
    "\n",
    "    #展平数据\n",
    "    input_ids = []\n",
    "    for i in data['input_ids']:\n",
    "        input_ids.extend(i)\n",
    "\n",
    "    #切断数据\n",
    "    data = {'input_ids': [], 'attention_mask': []}\n",
    "    for i in range(len(input_ids) // block_size):\n",
    "        block = input_ids[i * block_size:i * block_size + block_size]\n",
    "        data['input_ids'].append(block)\n",
    "        data['attention_mask'].append([1] * block_size)\n",
    "\n",
    "    #设置labels\n",
    "    data['labels'] = data['input_ids'].copy()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "dataset = dataset.map(\n",
    "    f,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405095b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5607,\n",
       " {'input_ids': tensor([[   11,   351,   393,  ..., 28177,   477,   286],\n",
       "          [  845,   880,  5600,  ...,    11,   339, 38383],\n",
       "          [ 5967,   326,   617,  ...,  4930,  2753,   257],\n",
       "          ...,\n",
       "          [ 3621,   284,   766,  ...,  8876,  8165,   284],\n",
       "          [  318,  6994,   337,  ...,  1577,   329,   777],\n",
       "          [  319,  8829,   810,  ...,   632,  5788,   617]]),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]),\n",
       "  'labels': tensor([[   11,   351,   393,  ..., 28177,   477,   286],\n",
       "          [  845,   880,  5600,  ...,    11,   339, 38383],\n",
       "          [ 5967,   326,   617,  ...,  4930,  2753,   257],\n",
       "          ...,\n",
       "          [ 3621,   284,   766,  ...,  8876,  8165,   284],\n",
       "          [  318,  6994,   337,  ...,  1577,   329,   777],\n",
       "          [  319,  8829,   810,  ...,   632,  5788,   617]])})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset['train'],\n",
    "    batch_size=8,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    break\n",
    "\n",
    "len(loader), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53f3c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16303.7184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.8249), torch.Size([8, 512, 50257]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, GPT2Model\n",
    "\n",
    "#加载模型\n",
    "#model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "\n",
    "\n",
    "#定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained = GPT2Model.from_pretrained('gpt2')\n",
    "        self.fc = torch.nn.Linear(768, tokenizer.vocab_size, bias=False)\n",
    "\n",
    "        #加载预训练模型的参数\n",
    "        parameters = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "        self.fc.load_state_dict(parameters.lm_head.state_dict())\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        logits = self.pretrained(input_ids=input_ids,\n",
    "                                 attention_mask=attention_mask)\n",
    "        logits = logits.last_hidden_state\n",
    "\n",
    "        logits = self.fc(logits)\n",
    "\n",
    "        shift_logits = logits[:, :-1].flatten(end_dim=1)\n",
    "        shift_labels = labels[:, 1:].flatten()\n",
    "\n",
    "        loss = self.criterion(shift_logits, shift_labels)\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits,\n",
    "        }\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd9b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 I love this guy and I'm really into him for sure.\"\n",
      "\n",
      "He was not available for comment.<|endoftext|>The US Department of Justice has issued\n",
      "1 I love this book! I will definitely be reading more!<|endoftext|>Here are links to video games you may have heard about in the past week or so\n",
      "2 I love this comic so much. Every action is hilarious and fun and a great way of showing off your awesome work. This may change over time and\n",
      "3 I love this game and can't wait to try this out.\"\n",
      "\n",
      "With these two names on the market next month, it makes sense to see\n",
      "4 I love this book and I can finally read every page of it on my Kindle!\"<|endoftext|>This item is no longer available. You will be receiving this\n"
     ]
    }
   ],
   "source": [
    "def generate(text):\n",
    "\n",
    "    def generate_loop(data):\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "\n",
    "        #取最后一个字\n",
    "        #[5, b, 50257]\n",
    "        out = out['logits']\n",
    "        #[5, 50257]\n",
    "        out = out[:, -1]\n",
    "\n",
    "        #第50大的值,以此为分界线,小于该值的全部赋值为负无穷\n",
    "        #[5, 50257] -> [5, 50]\n",
    "        topk_value = torch.topk(out, 50).values\n",
    "        #[5, 50] -> [5] -> [5, 1]\n",
    "        topk_value = topk_value[:, -1].unsqueeze(dim=1)\n",
    "\n",
    "        #赋值\n",
    "        #[5, 50257]\n",
    "        out = out.masked_fill(out < topk_value, -float('inf'))\n",
    "\n",
    "        #根据概率采样,无放回,所以不可能重复\n",
    "        #[5, 50257] -> [5, 1]\n",
    "        out = out.softmax(dim=1)\n",
    "        out = out.multinomial(num_samples=1)\n",
    "\n",
    "        data['input_ids'] = torch.cat([data['input_ids'], out], dim=1)\n",
    "        data['attention_mask'] = torch.ones_like(data['input_ids'])\n",
    "        data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "        if data['input_ids'].shape[1] >= 30:\n",
    "            return data\n",
    "\n",
    "        return generate_loop(data)\n",
    "\n",
    "    #重复5遍\n",
    "    data = tokenizer.batch_encode_plus([text] * 5, return_tensors='pt')\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "    data = generate_loop(data)\n",
    "\n",
    "    for i in range(5):\n",
    "        print(i, tokenizer.decode(data['input_ids'][i]))\n",
    "\n",
    "\n",
    "generate('I love this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0e6ed9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.95790696144104 1.9996433030140896e-05 0.29696673189823874\n",
      "50 4.074559688568115 1.981808453718566e-05 0.2967221135029354\n",
      "100 3.8087832927703857 1.9639736044230427e-05 0.3175146771037182\n",
      "150 3.982102155685425 1.9461387551275193e-05 0.30968688845401177\n",
      "200 3.8035480976104736 1.9283039058319958e-05 0.32093933463796476\n",
      "250 3.858929395675659 1.9104690565364724e-05 0.31237769080234834\n",
      "300 3.8749477863311768 1.892634207240949e-05 0.300880626223092\n",
      "350 3.9110424518585205 1.8747993579454255e-05 0.299412915851272\n",
      "400 3.6504409313201904 1.856964508649902e-05 0.336839530332681\n",
      "450 3.7060563564300537 1.8391296593543786e-05 0.3182485322896282\n",
      "500 3.8308796882629395 1.821294810058855e-05 0.31898238747553814\n",
      "550 3.9164681434631348 1.8034599607633317e-05 0.30552837573385516\n",
      "600 3.844902992248535 1.7856251114678083e-05 0.3148238747553816\n",
      "650 3.864423990249634 1.767790262172285e-05 0.31947162426614484\n",
      "700 3.9106669425964355 1.7499554128767614e-05 0.3084637964774951\n",
      "750 3.906909227371216 1.732120563581238e-05 0.2981898238747554\n",
      "800 3.666252374649048 1.7142857142857142e-05 0.32950097847358123\n",
      "850 3.8943099975585938 1.696450864990191e-05 0.2977005870841487\n",
      "900 3.6411843299865723 1.6786160156946676e-05 0.3373287671232877\n",
      "950 3.8402976989746094 1.660781166399144e-05 0.31262230919765166\n",
      "1000 3.9028067588806152 1.6429463171036208e-05 0.30039138943248533\n",
      "1050 3.813148260116577 1.6251114678080973e-05 0.29867906066536204\n",
      "1100 3.83650541305542 1.6072766185125735e-05 0.3065068493150685\n",
      "1150 3.836672306060791 1.5894417692170504e-05 0.3199608610567515\n",
      "1200 3.9207003116607666 1.5716069199215267e-05 0.2977005870841487\n",
      "1250 3.8301029205322266 1.5537720706260032e-05 0.3084637964774951\n",
      "1300 3.7733869552612305 1.53593722133048e-05 0.3204500978473581\n",
      "1350 3.712935447692871 1.5181023720349563e-05 0.32338551859099807\n",
      "1400 3.71645450592041 1.500267522739433e-05 0.31580234833659493\n",
      "1450 3.6923627853393555 1.4824326734439096e-05 0.3238747553816047\n",
      "1500 3.8980112075805664 1.464597824148386e-05 0.30601761252446186\n",
      "1550 3.7555572986602783 1.4467629748528626e-05 0.31898238747553814\n",
      "1600 3.7885677814483643 1.4289281255573391e-05 0.3050391389432485\n",
      "1650 3.7856693267822266 1.4110932762618157e-05 0.31580234833659493\n",
      "1700 3.945819139480591 1.3932584269662923e-05 0.3067514677103718\n",
      "1750 3.781489133834839 1.3754235776707688e-05 0.3030821917808219\n",
      "1800 3.949807643890381 1.3575887283752454e-05 0.3094422700587084\n",
      "1850 3.7092041969299316 1.339753879079722e-05 0.3282778864970646\n",
      "1900 3.639065980911255 1.3219190297841983e-05 0.33317025440313114\n",
      "1950 3.731398344039917 1.304084180488675e-05 0.31629158512720157\n",
      "2000 3.7599852085113525 1.2862493311931514e-05 0.3155577299412916\n",
      "2050 3.7448840141296387 1.268414481897628e-05 0.31922700587084146\n",
      "2100 3.7512755393981934 1.2505796326021047e-05 0.311399217221135\n",
      "2150 3.668710947036743 1.2327447833065811e-05 0.33145792563600784\n",
      "2200 3.8203368186950684 1.2149099340110577e-05 0.32069471624266144\n",
      "2250 3.7193143367767334 1.1970750847155344e-05 0.31433463796477495\n",
      "2300 3.637777090072632 1.1792402354200108e-05 0.32901174168297453\n",
      "2350 3.5925703048706055 1.1614053861244874e-05 0.3321917808219178\n",
      "2400 3.8248887062072754 1.1435705368289637e-05 0.3184931506849315\n",
      "2450 3.8335282802581787 1.1257356875334405e-05 0.31262230919765166\n",
      "2500 3.6701722145080566 1.107900838237917e-05 0.32974559686888455\n",
      "2550 3.7517778873443604 1.0900659889423934e-05 0.3336594911937378\n",
      "2600 3.7928311824798584 1.0722311396468702e-05 0.31531311154598823\n",
      "2650 3.776724100112915 1.0543962903513467e-05 0.31727005870841485\n",
      "2700 3.6538374423980713 1.0365614410558231e-05 0.3282778864970646\n",
      "2750 3.605351448059082 1.0187265917602998e-05 0.33145792563600784\n",
      "2800 3.8086135387420654 1.0008917424647762e-05 0.3099315068493151\n",
      "2850 3.765681028366089 9.830568931692528e-06 0.3155577299412916\n",
      "2900 3.827010154724121 9.652220438737293e-06 0.3065068493150685\n",
      "2950 3.8106892108917236 9.473871945782059e-06 0.3111545988258317\n",
      "3000 3.8308298587799072 9.295523452826825e-06 0.3148238747553816\n",
      "3050 3.679182767868042 9.11717495987159e-06 0.33659491193737767\n",
      "3100 3.6600501537323 8.938826466916356e-06 0.312866927592955\n",
      "3150 3.833733320236206 8.760477973961121e-06 0.32069471624266144\n",
      "3200 3.953687906265259 8.582129481005887e-06 0.30895303326810175\n",
      "3250 3.8430516719818115 8.403780988050651e-06 0.31702544031311153\n",
      "3300 3.8060572147369385 8.225432495095416e-06 0.31775929549902154\n",
      "3350 3.7004477977752686 8.047084002140184e-06 0.32338551859099807\n",
      "3400 3.7278597354888916 7.868735509184948e-06 0.31531311154598823\n",
      "3450 3.884218454360962 7.690387016229713e-06 0.3221624266144814\n",
      "3500 3.797771692276001 7.512038523274479e-06 0.30968688845401177\n",
      "3550 3.670816421508789 7.333690030319245e-06 0.32803326810176126\n",
      "3600 3.769094705581665 7.15534153736401e-06 0.3165362035225049\n",
      "3650 3.7626211643218994 6.976993044408776e-06 0.312133072407045\n",
      "3700 3.817925453186035 6.79864455145354e-06 0.32265166340508805\n",
      "3750 3.723731517791748 6.620296058498307e-06 0.31090998043052837\n",
      "3800 3.722511053085327 6.4419475655430715e-06 0.32167318982387477\n",
      "3850 3.6738686561584473 6.263599072587837e-06 0.32265166340508805\n",
      "3900 3.804495096206665 6.085250579632602e-06 0.3150684931506849\n",
      "3950 3.7355904579162598 5.906902086677368e-06 0.3148238747553816\n",
      "4000 3.6564483642578125 5.728553593722134e-06 0.33170254403131116\n",
      "4050 3.8335440158843994 5.550205100766899e-06 0.3062622309197652\n",
      "4100 3.7350215911865234 5.371856607811664e-06 0.31531311154598823\n",
      "4150 3.598924160003662 5.193508114856431e-06 0.34173189823874756\n",
      "4200 3.760550022125244 5.0151596219011954e-06 0.3184931506849315\n",
      "4250 3.6987383365631104 4.836811128945961e-06 0.3221624266144814\n",
      "4300 3.7880985736846924 4.658462635990727e-06 0.31066536203522505\n",
      "4350 3.580073833465576 4.480114143035491e-06 0.3456457925636008\n",
      "4400 3.802724838256836 4.301765650080257e-06 0.30724070450097846\n",
      "4450 3.74603009223938 4.1234171571250226e-06 0.31947162426614484\n",
      "4500 3.5837223529815674 3.945068664169788e-06 0.34319960861056753\n",
      "4550 3.7853188514709473 3.7667201712145533e-06 0.32289628180039137\n",
      "4600 3.7897562980651855 3.5883716782593193e-06 0.30724070450097846\n",
      "4650 3.737487554550171 3.4100231853040845e-06 0.32142857142857145\n",
      "4700 3.690072774887085 3.23167469234885e-06 0.31947162426614484\n",
      "4750 3.7758517265319824 3.0533261993936153e-06 0.3184931506849315\n",
      "4800 3.713803291320801 2.874977706438381e-06 0.33512720156555775\n",
      "4850 3.6515538692474365 2.696629213483146e-06 0.32142857142857145\n",
      "4900 3.8095450401306152 2.518280720527912e-06 0.32142857142857145\n",
      "4950 3.77828311920166 2.3399322275726772e-06 0.30870841487279843\n",
      "5000 3.7016003131866455 2.1615837346174424e-06 0.3304794520547945\n",
      "5050 3.8449628353118896 1.983235241662208e-06 0.33439334637964774\n",
      "5100 3.525289297103882 1.8048867487069736e-06 0.33439334637964774\n",
      "5150 3.8524112701416016 1.626538255751739e-06 0.30968688845401177\n",
      "5200 3.7240686416625977 1.4481897627965043e-06 0.3133561643835616\n",
      "5250 3.586726427078247 1.26984126984127e-06 0.336839530332681\n",
      "5300 3.6986827850341797 1.0914927768860355e-06 0.3270547945205479\n",
      "5350 3.6930429935455322 9.131442839308009e-07 0.33659491193737767\n",
      "5400 3.772307872772217 7.347957909755663e-07 0.3187377690802348\n",
      "5450 3.775899887084961 5.564472980203318e-07 0.3138454011741683\n",
      "5500 3.6071622371673584 3.780988050650972e-07 0.32901174168297453\n",
      "5550 3.732058525085449 1.9975031210986268e-07 0.32950097847358123\n",
      "5600 3.7195942401885986 2.1401819154628145e-08 0.31971624266144816\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "\n",
    "#训练\n",
    "def train():\n",
    "    global model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0,\n",
    "                              num_training_steps=len(loader),\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            labels = data['labels'][:, 1:]\n",
    "            out = out['logits'].argmax(dim=2)[:, :-1]\n",
    "\n",
    "            accuracy = (labels == out).sum().item() / labels.numel()\n",
    "\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "            print(i, loss.item(), lr, accuracy)\n",
    "\n",
    "    model = model.to('cpu')\n",
    "    torch.save(model, 'models/8.生成.model')\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c6a16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 I love this movie, I love it. It's about a guy in a small town, trying to be a good father(...I mean,\n",
      "1 I love this film; I even enjoyed it in the 80's! However, I can't get too much into it.This is truly a great\n",
      "2 I love this movie. Some movies with bad actors and actresses would have more of a reason but The Dictator is one of the best documentaries I\n",
      "3 I love this is one of them!! I even wrote my Oscar for this film when it was released in 1988. Great documentary to watch, especially when\n",
      "4 I love this movie but I think it is rubbish. There are only ten people worth watching who are not good but these people are as annoying as the\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('models/8.生成.model')\n",
    "generate('I love this')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
