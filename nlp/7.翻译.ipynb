{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175d98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÂÖ®Â±ÄÂèòÈáè\n",
    "hub_token = open('/root/hub_token.txt').read().strip()\n",
    "repo_id = 'lansinuote/nlp.7.translation'\n",
    "push_to_hub = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2e6ab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-ro', vocab_size=59543, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt39/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[125, 778, 3, 63, 141, 9191, 23, 187, 32, 716, 9191, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#Âä†ËΩΩÁºñÁ†ÅÂô®\n",
    "tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-ro',\n",
    "                                          use_fast=True)\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#ÁºñÁ†ÅËØïÁÆó\n",
    "tokenizer.batch_encode_plus(\n",
    "    [['Hello, this one sentence!', 'This is another sentence.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c480e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt16 (/root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9932fc2f0e1f4719b9ebe2390aae225d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-e153bf661ff30a9d.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-04de8b997cf89dc0.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-d85cda4b0f38d63d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-eac92af555fe1778.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-6dc27e6d44541abb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-149277764173b741.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-b9361274081abe39.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-ab32c4661007c50a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-41717b778c569610.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-98dc5be658a8c705.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-7b3c2913ad26c529.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-6ee305e524c9634d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-1fc207dafc588430.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-9332ebe962b2e78b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-568c51836bb49cf3.arrow\n",
      "Pushing split train to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95db58d8f39443cf851cb4148ca83955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1b6bbfced44fb8b42de6a5223f353a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n",
      "Resuming upload of the dataset shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d819f202f2df4547bafb82aa20362a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--nlp.7.translation-9ebe5b45a0781875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.7.translation-9ebe5b45a0781875/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426c1f579ee141db8bd1bfcd15b9d729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a868adcd37ad49f7b1a4c4a8733b111e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/40.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fcebfb8e5a423ea730d1f3cdd91b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/40.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c174a91f1a41a88eb5f97bffa08f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c77834db134118bd7baef8db555ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--nlp.7.translation-9ebe5b45a0781875/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1dbbcd935a4e709ebd93b1377a9335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "}) {'input_ids': [460, 354, 3794, 12, 10677, 20, 5046, 14, 4, 2546, 37, 8, 397, 5551, 30, 10113, 37, 3501, 19814, 18, 8465, 20, 4, 44690, 782, 2, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [902, 576, 2946, 76, 10815, 17, 5098, 14997, 5, 559, 1140, 43, 2434, 6624, 27, 50, 337, 19216, 46, 22174, 17, 2317, 121, 16825, 2, 0]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    #Âä†ËΩΩÊï∞ÊçÆ\n",
    "    dataset = load_dataset(path='wmt16', name='ro-en')\n",
    "\n",
    "    #ÈááÊ†∑,Êï∞ÊçÆÈáèÂ§™Â§ß‰∫ÜË∑ë‰∏çÂä®\n",
    "    dataset['train'] = dataset['train'].shuffle(1).select(range(20000))\n",
    "    dataset['validation'] = dataset['validation'].shuffle(1).select(range(200))\n",
    "    dataset['test'] = dataset['test'].shuffle(1).select(range(200))\n",
    "\n",
    "    #Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\n",
    "    def preprocess_function(data):\n",
    "        #ÂèñÂá∫Êï∞ÊçÆ‰∏≠ÁöÑenÂíåro\n",
    "        en = [ex['en'] for ex in data['translation']]\n",
    "        ro = [ex['ro'] for ex in data['translation']]\n",
    "\n",
    "        #Ê∫êËØ≠Ë®ÄÁõ¥Êé•ÁºñÁ†ÅÂ∞±Ë°å‰∫Ü\n",
    "        data = tokenizer.batch_encode_plus(en, max_length=128, truncation=True)\n",
    "\n",
    "        #ÁõÆÊ†áËØ≠Ë®ÄÂú®ÁâπÊÆäÊ®°Âùó‰∏≠ÁºñÁ†Å\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            data['labels'] = tokenizer.batch_encode_plus(\n",
    "                ro, max_length=128, truncation=True)['input_ids']\n",
    "\n",
    "        return data\n",
    "\n",
    "    dataset = dataset.map(function=preprocess_function,\n",
    "                          batched=True,\n",
    "                          batch_size=1000,\n",
    "                          num_proc=4,\n",
    "                          remove_columns=['translation'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    dataset = get_dataset()\n",
    "    dataset.push_to_hub(repo_id=repo_id, token=hub_token)\n",
    "\n",
    "#Áõ¥Êé•‰ΩøÁî®ÊàëÂ§ÑÁêÜÂ•ΩÁöÑÊï∞ÊçÆÈõÜ\n",
    "dataset = load_dataset(path=repo_id)\n",
    "\n",
    "print(dataset, dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1f61fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[59542, 10455,   120,    80],\n",
       "        [59542,   301,    53,  4074]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ëøô‰∏™ÂáΩÊï∞Âíå‰∏ãÈù¢Ëøô‰∏™Â∑•ÂÖ∑Á±ªÁ≠â‰ª∑,‰ΩÜÊàë‰πüÊòØÊ®°‰ªøÂÆûÁé∞ÁöÑ,‰∏çÁ°ÆÂÆöÊúâÊ≤°ÊúâÂá∫ÂÖ•\n",
    "#from transformers import DataCollatorForSeq2Seq\n",
    "#DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "#Êï∞ÊçÆÊâπÂ§ÑÁêÜÂáΩÊï∞\n",
    "def collate_fn(data):\n",
    "    #Ê±ÇÊúÄÈïøÁöÑlabel\n",
    "    max_length = max([len(i['labels']) for i in data])\n",
    "\n",
    "    #ÊääÊâÄÊúâÁöÑlabelÈÉΩË°•padÂà∞ÊúÄÈïø\n",
    "    for i in data:\n",
    "        pads = [-100] * (max_length - len(i['labels']))\n",
    "        i['labels'] = i['labels'] + pads\n",
    "\n",
    "    #ÊääÂ§ö‰∏™Êï∞ÊçÆÊï¥ÂêàÊàê‰∏Ä‰∏™tensor\n",
    "    data = tokenizer.pad(\n",
    "        encoded_inputs=data,\n",
    "        padding=True,\n",
    "        max_length=None,\n",
    "        pad_to_multiple_of=None,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    #ÂÆö‰πâdecoder_input_ids\n",
    "    data['decoder_input_ids'] = torch.full_like(data['labels'],\n",
    "                                                tokenizer.get_vocab()['<pad>'],\n",
    "                                                dtype=torch.long)\n",
    "    data['decoder_input_ids'][:, 1:] = data['labels'][:, :-1]\n",
    "    data['decoder_input_ids'][data['decoder_input_ids'] ==\n",
    "                              -100] = tokenizer.get_vocab()['<pad>']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = [{\n",
    "    'input_ids': [21603, 10, 37, 3719, 13],\n",
    "    'attention_mask': [1, 1, 1, 1, 1],\n",
    "    'labels': [10455, 120, 80]\n",
    "}, {\n",
    "    'input_ids': [21603, 10, 7086, 8408, 563],\n",
    "    'attention_mask': [1, 1, 1, 1, 1],\n",
    "    'labels': [301, 53, 4074, 1669]\n",
    "}]\n",
    "\n",
    "collate_fn(data)['decoder_input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad1647a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([8, 38]) tensor([[   68,   346,    32,  1305,    13,   408,    45,  4682,  8355, 21463,\n",
      "           101,  2868,  5941,     4,   530,   143,   246,     2,     0, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542],\n",
      "        [  115,    64, 10096,  2649,   131,     4,  1824, 36635,    20, 22789,\n",
      "           433,     4, 24505,     2,     0, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542]])\n",
      "attention_mask torch.Size([8, 38]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "labels torch.Size([8, 45]) tensor([[  694,    55,  9685,    19, 20596, 17061,  4682,    43, 12434,    19,\n",
      "           227,  7358,  6531,  3835,  1649,     2,     0,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100],\n",
      "        [  119,  1734,  7772,   255,  6291, 21634,    17, 22789,   563,     5,\n",
      "         20326,     2,     0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100]])\n",
      "decoder_input_ids torch.Size([8, 45]) tensor([[59542,   694,    55,  9685,    19, 20596, 17061,  4682,    43, 12434,\n",
      "            19,   227,  7358,  6531,  3835,  1649,     2,     0, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542],\n",
      "        [59542,   119,  1734,  7772,   255,  6291, 21634,    17, 22789,   563,\n",
      "             5, 20326,     2,     0, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542, 59542,\n",
      "         59542, 59542, 59542, 59542, 59542]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Êï∞ÊçÆÂä†ËΩΩÂô®\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset['train'],\n",
    "    batch_size=8,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    break\n",
    "\n",
    "for k, v in data.items():\n",
    "    print(k, v.shape, v[:2])\n",
    "\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9488731",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Helsinki-NLP/opus-mt-en-ro were not used when initializing MarianModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing MarianModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MarianModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10563.4816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.3505, grad_fn=<NllLossBackward0>), torch.Size([8, 45, 59543]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, MarianModel, PreTrainedModel, PretrainedConfig\n",
    "\n",
    "#Âä†ËΩΩÊ®°Âûã\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-en-ro')\n",
    "\n",
    "\n",
    "#ÂÆö‰πâ‰∏ãÊ∏∏‰ªªÂä°Ê®°Âûã\n",
    "class Model(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.pretrained = MarianModel.from_pretrained(\n",
    "            'Helsinki-NLP/opus-mt-en-ro')\n",
    "\n",
    "        self.register_buffer('final_logits_bias',\n",
    "                             torch.zeros(1, tokenizer.vocab_size))\n",
    "\n",
    "        self.fc = torch.nn.Linear(512, tokenizer.vocab_size, bias=False)\n",
    "\n",
    "        #Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÂèÇÊï∞\n",
    "        parameters = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            'Helsinki-NLP/opus-mt-en-ro')\n",
    "        self.fc.load_state_dict(parameters.lm_head.state_dict())\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels, decoder_input_ids):\n",
    "        logits = self.pretrained(input_ids=input_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 decoder_input_ids=decoder_input_ids)\n",
    "        logits = logits.last_hidden_state\n",
    "\n",
    "        logits = self.fc(logits) + self.final_logits_bias\n",
    "\n",
    "        loss = self.criterion(logits.flatten(end_dim=1), labels.flatten())\n",
    "\n",
    "        return {'loss': loss, 'logits': logits}\n",
    "\n",
    "\n",
    "model = Model(PretrainedConfig())\n",
    "\n",
    "#ÁªüËÆ°ÂèÇÊï∞Èáè\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f3263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26234/1560569803.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(path='sacrebleu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.0,\n",
       " 'counts': [4, 2, 0, 0],\n",
       " 'totals': [4, 2, 0, 0],\n",
       " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "#Âä†ËΩΩËØÑ‰ª∑ÂáΩÊï∞\n",
    "metric = load_metric(path='sacrebleu')\n",
    "\n",
    "#ËØïÁÆó\n",
    "metric.compute(predictions=['hello there', 'general kenobi'],\n",
    "               references=[['hello there'], ['general kenobi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c924a315",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input_ids= You are a‚ñÅgreat‚ñÅpower‚ñÅonly‚ñÅif you‚ñÅhave‚ñÅsolutions.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= E≈üt tu o, doar daca ai solu solu»õiitii.</s>,,,,,-- - - - Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu Tu\n",
      "label= <pad> Dar esti mare putere doar daca ai »ôi solutii.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "2\n",
      "input_ids= I‚ñÅcan‚ñÅguarantee‚ñÅwe‚ñÅhaven't‚ñÅchanged‚ñÅnothing‚ñÅall‚ñÅyear with‚ñÅour‚ñÅdefensive‚ñÅsystems or‚ñÅtechniques,‚ñÅit's‚ñÅjust that the‚ñÅlast‚ñÅsix‚ñÅweeks‚ñÅwe‚ñÅhave‚ñÅmade a real‚ñÅemphasis with‚ñÅour contact in‚ñÅtackles and that‚ñÅhas‚ñÅbeen the turn‚ñÅaround for us.</s>\n",
      "pred= Pot garanta cƒÉ n am schimbat nimic tot anul cu sistemele noastre tehnicile noastre defensive, doara timp cƒÉ ultimele ultimele ≈üase sƒÉptƒÉm√¢ni am pus un pe-adevƒÉr pe contactele abordai, asta ne fost lucrurile noastrƒÉ</s>\n",
      "label= <pad> Pot garanta cƒÉ nu am schimbat nimic tot anul √Æn sistemele sau tehnicile noastre defensive, at√¢ta doar cƒÉ √Æn ultimele »ôase sƒÉptƒÉm√¢ni am pus accentul √Æntr-adevƒÉr pe contact √Æn placƒÉri »ôi astfel am schimbat situa»õia.\n",
      "4\n",
      "input_ids= In‚ñÅItaly, Salvatore and‚ñÅhis‚ñÅwife‚ñÅexplained to the‚ñÅgirl‚ñÅabout her‚ñÅorigins and that her past‚ñÅlinks her to‚ñÅRomania.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= √én Italia, Salvae »ôi so»õia sa-au explicat fetei despre origini provine, cƒÉ trecutul ei o leagƒÉ de Rom√¢nia.</s>,ulul Ea √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én √én\n",
      "label= <pad> √én Italia, Salvadore »ôi so»õia i-au explicat fetei de unde vine »ôi cƒÉ trecutul ei o leagƒÉ de Rom√¢nia.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "6\n",
      "input_ids= ‚ñÅFew‚ñÅgive‚ñÅJeremy Corbyn a real‚ñÅchance to‚ñÅever‚ñÅbecome prime minister.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Pu≈£in»õini dau dau lui reale lui Jeremy Corbyn sƒÉ devinƒÉ vreodatƒÉ prim-.</s>,, Jer Jer Jer Jer Jer Jer Jer Jer Jer Jer Jer Jer Pu≈£in Pu≈£in Pu≈£in Pu≈£in Pu≈£in Pu≈£in Pu≈£in Pu≈£in Pu≈£in Pu≈£in\n",
      "label= <pad> Pu»õini √Æi dau »ôanse reale lui Jeremy Corbyn sƒÉ ajungƒÉ vreodatƒÉ prim ministru.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "8\n",
      "input_ids= An editorial in the Lancet medical‚ñÅjournal‚ñÅlast‚ñÅmonth‚ñÅattacked the \"extraordinarily‚ñÅflimsy‚ñÅfoundation\" on‚ñÅwhich PHE‚ñÅbased‚ñÅits‚ñÅmain‚ñÅconclusion.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Un editorial din luna trecutƒÉ √Æn revista medicalƒÉ Lancet a atacat \",F extrem de sub≈£ireƒÉ pe, care PH-a bazat PHE concluzia principalƒÉ.</s> DE Edi Edi La La = = = = = = = = = = Un Un Un Un Un Un Un Un Un Un Un Un Un Un Un Un\n",
      "label= <pad> Un articol publicat luna trecutƒÉ √Æn revista medicalƒÉ Lancet a atacat <unk> baza extraordinar de fragilƒÉ<unk> pe care »ôi-a fondat PHE concluzia principalƒÉ.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "10\n",
      "input_ids= Corneliu Vadim Tudor‚ñÅwas‚ñÅborn on‚ñÅNovember 28,‚ñÅ1949, in‚ñÅBucharest. He‚ñÅwas a‚ñÅwriter,‚ñÅpolitician and‚ñÅjournalist.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Corneliu Vadim Tudor s-a nƒÉscutscut pe 28 noiembrie 1949, la Bucuresti, scriitor scriitor, politician si jurnalist.</s>, al al al al al al al al al I I I I I I I I I I √én √én √én √én √én √én √én\n",
      "label= <pad> Corneliu Vadim Tudor s-a nascut √Æn 28 noiembrie 1949, √Æn Bucuresti, era scriitor, politician »ôi jurnalist.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "{'score': 7.704088373017681, 'counts': [1702, 1141, 807, 563], 'totals': [4631, 4543, 4455, 4367], 'precisions': [36.75232131289138, 25.115562403697997, 18.114478114478114, 12.892145637737578], 'bp': 0.35754159894027016, 'sys_len': 4631, 'ref_len': 9394}\n"
     ]
    }
   ],
   "source": [
    "#ÊµãËØï\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    #Êï∞ÊçÆÂä†ËΩΩÂô®\n",
    "    loader_test = torch.utils.data.DataLoader(\n",
    "        dataset=dataset['test'],\n",
    "        batch_size=8,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for i, data in enumerate(loader_test):\n",
    "        #ËÆ°ÁÆó\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "\n",
    "        pred = tokenizer.batch_decode(out['logits'].argmax(dim=2))\n",
    "        label = tokenizer.batch_decode(data['decoder_input_ids'])\n",
    "        predictions.extend(pred)\n",
    "        references.extend(label)\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            print(i)\n",
    "            input_ids = tokenizer.decode(data['input_ids'][0])\n",
    "\n",
    "            print('input_ids=', input_ids)\n",
    "            print('pred=', pred[0])\n",
    "            print('label=', label[0])\n",
    "\n",
    "        if i == 10:\n",
    "            break\n",
    "\n",
    "    references = [[j] for j in references]\n",
    "    metric_out = metric.compute(predictions=predictions, references=references)\n",
    "    print(metric_out)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1375fcad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pt39/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4797824621200562 0.0 {'score': 9.120008577043292, 'counts': [221, 179, 149, 124], 'totals': [588, 580, 572, 564], 'precisions': [37.585034013605444, 30.862068965517242, 26.04895104895105, 21.98581560283688], 'bp': 0.31944937686506625, 'sys_len': 588, 'ref_len': 1259} 1.9992e-05\n",
      "50 1.293352723121643 0.0 {'score': 7.44164783389345, 'counts': [211, 153, 114, 87], 'totals': [578, 570, 562, 554], 'precisions': [36.50519031141869, 26.842105263157894, 20.284697508896798, 15.703971119133573], 'bp': 0.31483413242798336, 'sys_len': 578, 'ref_len': 1246} 1.9592e-05\n",
      "100 0.885346531867981 0.0033783783783783786 {'score': 6.751734803815611, 'counts': [201, 142, 104, 75], 'totals': [573, 565, 557, 549], 'precisions': [35.07853403141361, 25.13274336283186, 18.671454219030522, 13.66120218579235], 'bp': 0.31004753070168034, 'sys_len': 573, 'ref_len': 1244} 1.9192000000000002e-05\n",
      "150 0.8533743619918823 0.0 {'score': 13.686218267242388, 'counts': [171, 123, 94, 70], 'totals': [352, 344, 336, 328], 'precisions': [48.57954545454545, 35.75581395348837, 27.976190476190474, 21.341463414634145], 'bp': 0.4288745148193968, 'sys_len': 352, 'ref_len': 650} 1.8792000000000002e-05\n",
      "200 0.9598424434661865 0.006696428571428571 {'score': 11.613237056699216, 'counts': [189, 142, 111, 90], 'totals': [428, 420, 412, 404], 'precisions': [44.1588785046729, 33.80952380952381, 26.941747572815533, 22.277227722772277], 'bp': 0.3774568334075752, 'sys_len': 428, 'ref_len': 845} 1.8392e-05\n",
      "250 1.1830499172210693 0.0018656716417910447 {'score': 9.33844881232761, 'counts': [195, 140, 105, 79], 'totals': [505, 497, 489, 481], 'precisions': [38.613861386138616, 28.169014084507044, 21.47239263803681, 16.424116424116423], 'bp': 0.3752367871797581, 'sys_len': 505, 'ref_len': 1000} 1.7992e-05\n",
      "300 1.2433003187179565 0.005747126436781609 {'score': 7.525276183479098, 'counts': [220, 156, 125, 101], 'totals': [731, 723, 715, 707], 'precisions': [30.095759233926128, 21.57676348547718, 17.482517482517483, 14.285714285714286], 'bp': 0.37499291249083483, 'sys_len': 731, 'ref_len': 1448} 1.7592000000000004e-05\n",
      "350 1.0052417516708374 0.0 {'score': 16.42540458968082, 'counts': [152, 114, 92, 71], 'totals': [300, 292, 284, 276], 'precisions': [50.666666666666664, 39.04109589041096, 32.394366197183096, 25.72463768115942], 'bp': 0.4584060113052235, 'sys_len': 300, 'ref_len': 534} 1.7192e-05\n",
      "400 0.8489341735839844 0.003472222222222222 {'score': 25.45038314826629, 'counts': [165, 121, 98, 82], 'totals': [277, 269, 261, 253], 'precisions': [59.56678700361011, 44.98141263940521, 37.547892720306514, 32.41106719367589], 'bp': 0.5989151287945745, 'sys_len': 277, 'ref_len': 419} 1.6792e-05\n",
      "450 1.025385856628418 0.0045045045045045045 {'score': 6.321613087405688, 'counts': [277, 201, 153, 114], 'totals': [860, 852, 844, 836], 'precisions': [32.2093023255814, 23.591549295774648, 18.127962085308056, 13.636363636363637], 'bp': 0.3036557971960769, 'sys_len': 860, 'ref_len': 1885} 1.6392e-05\n",
      "500 0.5974541902542114 0.009615384615384616 {'score': 15.895866947214195, 'counts': [210, 162, 132, 106], 'totals': [419, 411, 403, 395], 'precisions': [50.11933174224344, 39.416058394160586, 32.754342431761785, 26.835443037974684], 'bp': 0.43789520451776154, 'sys_len': 419, 'ref_len': 765} 1.5992000000000002e-05\n",
      "550 0.6576382517814636 0.005434782608695652 {'score': 16.404655608983962, 'counts': [178, 135, 114, 96], 'totals': [368, 360, 352, 344], 'precisions': [48.369565217391305, 37.5, 32.38636363636363, 27.906976744186046], 'bp': 0.4584558407536559, 'sys_len': 368, 'ref_len': 655} 1.5592e-05\n",
      "600 0.9891085624694824 0.004807692307692308 {'score': 12.138898985258201, 'counts': [182, 124, 93, 67], 'totals': [391, 383, 375, 367], 'precisions': [46.547314578005114, 32.37597911227154, 24.8, 18.256130790190735], 'bp': 0.4223619702817352, 'sys_len': 391, 'ref_len': 728} 1.5192000000000003e-05\n",
      "650 0.6127076745033264 0.009615384615384616 {'score': 32.38544440960212, 'counts': [205, 163, 135, 111], 'totals': [310, 302, 294, 286], 'precisions': [66.12903225806451, 53.973509933774835, 45.91836734693877, 38.81118881118881], 'bp': 0.6448679721892344, 'sys_len': 310, 'ref_len': 446} 1.4792000000000002e-05\n",
      "700 0.8210155367851257 0.005434782608695652 {'score': 18.372122576609478, 'counts': [183, 139, 106, 81], 'totals': [356, 348, 340, 332], 'precisions': [51.40449438202247, 39.94252873563219, 31.176470588235293, 24.397590361445783], 'bp': 0.5197047682409304, 'sys_len': 356, 'ref_len': 589} 1.4392000000000002e-05\n",
      "750 0.8817370533943176 0.002551020408163265 {'score': 12.722478437317408, 'counts': [189, 132, 96, 68], 'totals': [406, 398, 390, 382], 'precisions': [46.55172413793103, 33.165829145728644, 24.615384615384617, 17.801047120418847], 'bp': 0.4436107094018198, 'sys_len': 406, 'ref_len': 736} 1.3992000000000001e-05\n",
      "800 0.6331095695495605 0.00625 {'score': 10.928230687356402, 'counts': [199, 143, 108, 82], 'totals': [459, 451, 443, 435], 'precisions': [43.35511982570806, 31.70731707317073, 24.37923250564334, 18.850574712643677], 'bp': 0.3876267378278905, 'sys_len': 459, 'ref_len': 894} 1.3592000000000001e-05\n",
      "850 0.7867997884750366 0.005 {'score': 8.328081352129253, 'counts': [225, 159, 114, 84], 'totals': [587, 579, 571, 563], 'precisions': [38.33049403747871, 27.46113989637306, 19.964973730297725, 14.920071047957371], 'bp': 0.3519405480154652, 'sys_len': 587, 'ref_len': 1200} 1.3192e-05\n",
      "900 0.694574773311615 0.008064516129032258 {'score': 15.35218989870982, 'counts': [230, 178, 146, 122], 'totals': [481, 473, 465, 457], 'precisions': [47.817047817047815, 37.63213530655391, 31.397849462365592, 26.695842450765863], 'bp': 0.4380755804601984, 'sys_len': 481, 'ref_len': 878} 1.2792e-05\n",
      "950 0.733869731426239 0.00641025641025641 {'score': 19.02747660424653, 'counts': [175, 131, 105, 86], 'totals': [327, 319, 311, 303], 'precisions': [53.51681957186544, 41.06583072100314, 33.762057877813504, 28.382838283828384], 'bp': 0.499479060623208, 'sys_len': 327, 'ref_len': 554} 1.2392000000000003e-05\n",
      "1000 0.8266855478286743 0.005067567567567568 {'score': 6.819899660461278, 'counts': [189, 139, 107, 85], 'totals': [559, 551, 543, 535], 'precisions': [33.810375670840784, 25.226860254083483, 19.70534069981584, 15.88785046728972], 'bp': 0.30001116172008474, 'sys_len': 559, 'ref_len': 1232} 1.1992000000000001e-05\n",
      "1050 0.9551225900650024 0.0031645569620253164 {'score': 4.813186864517226, 'counts': [174, 119, 89, 71], 'totals': [645, 637, 629, 621], 'precisions': [26.976744186046513, 18.681318681318682, 14.149443561208267, 11.43317230273752], 'bp': 0.28484390415198974, 'sys_len': 645, 'ref_len': 1455} 1.1592000000000002e-05\n",
      "1100 0.8034053444862366 0.0025 {'score': 10.073388836894791, 'counts': [154, 115, 85, 63], 'totals': [383, 375, 367, 359], 'precisions': [40.2088772845953, 30.666666666666668, 23.160762942779293, 17.54874651810585], 'bp': 0.37859835946871206, 'sys_len': 383, 'ref_len': 755} 1.1192e-05\n",
      "1150 0.5552195310592651 0.007211538461538462 {'score': 18.82198486205154, 'counts': [202, 163, 140, 123], 'totals': [394, 386, 378, 370], 'precisions': [51.26903553299493, 42.2279792746114, 37.03703703703704, 33.24324324324324], 'bp': 0.4658184137495495, 'sys_len': 394, 'ref_len': 695} 1.0792000000000001e-05\n",
      "1200 0.695573627948761 0.004518072289156626 {'score': 9.291763701551302, 'counts': [256, 191, 146, 111], 'totals': [640, 632, 624, 616], 'precisions': [40.0, 30.22151898734177, 23.397435897435898, 18.01948051948052], 'bp': 0.3477574586840902, 'sys_len': 640, 'ref_len': 1316} 1.0392e-05\n",
      "1250 0.819365918636322 0.008152173913043478 {'score': 13.632236028910249, 'counts': [171, 130, 101, 77], 'totals': [371, 363, 355, 347], 'precisions': [46.091644204851754, 35.81267217630854, 28.450704225352112, 22.19020172910663], 'bp': 0.42666674738059074, 'sys_len': 371, 'ref_len': 687} 9.992e-06\n",
      "1300 0.9107105731964111 0.006818181818181818 {'score': 14.549305368024523, 'counts': [190, 139, 108, 82], 'totals': [407, 399, 391, 383], 'precisions': [46.68304668304668, 34.83709273182957, 27.62148337595908, 21.409921671018278], 'bp': 0.4645970693408125, 'sys_len': 407, 'ref_len': 719} 9.592e-06\n",
      "1350 1.130139708518982 0.002232142857142857 {'score': 9.826719871623247, 'counts': [177, 124, 101, 81], 'totals': [410, 402, 394, 386], 'precisions': [43.170731707317074, 30.845771144278608, 25.634517766497463, 20.984455958549223], 'bp': 0.3377781859012509, 'sys_len': 410, 'ref_len': 855} 9.192000000000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 0.5198501944541931 0.004901960784313725 {'score': 10.956261133157897, 'counts': [168, 137, 117, 101], 'totals': [411, 403, 395, 387], 'precisions': [40.87591240875913, 33.99503722084367, 29.620253164556964, 26.098191214470283], 'bp': 0.34032341912768727, 'sys_len': 411, 'ref_len': 854} 8.792e-06\n",
      "1450 1.1050782203674316 0.0 {'score': 13.610779822702535, 'counts': [215, 156, 118, 87], 'totals': [472, 464, 456, 448], 'precisions': [45.55084745762712, 33.62068965517241, 25.87719298245614, 19.419642857142858], 'bp': 0.45953398785509414, 'sys_len': 472, 'ref_len': 839} 8.392e-06\n",
      "1500 0.7206818461418152 0.0055147058823529415 {'score': 11.547276583069706, 'counts': [219, 178, 151, 128], 'totals': [521, 513, 505, 497], 'precisions': [42.034548944337814, 34.69785575048733, 29.900990099009903, 25.75452716297787], 'bp': 0.35470517407082913, 'sys_len': 521, 'ref_len': 1061} 7.992e-06\n",
      "1550 0.9179471135139465 0.002976190476190476 {'score': 14.694674582896523, 'counts': [162, 117, 94, 76], 'totals': [331, 323, 315, 307], 'precisions': [48.94259818731118, 36.22291021671827, 29.841269841269842, 24.7557003257329], 'bp': 0.4343794326705179, 'sys_len': 331, 'ref_len': 607} 7.592e-06\n",
      "1600 1.0173852443695068 0.00423728813559322 {'score': 8.18403911648738, 'counts': [171, 113, 80, 54], 'totals': [458, 450, 442, 434], 'precisions': [37.33624454148472, 25.11111111111111, 18.099547511312217, 12.442396313364055], 'bp': 0.3817909406122358, 'sys_len': 458, 'ref_len': 899} 7.192e-06\n",
      "1650 0.8650031089782715 0.005597014925373134 {'score': 11.037164425091765, 'counts': [220, 164, 126, 96], 'totals': [526, 518, 510, 502], 'precisions': [41.82509505703422, 31.66023166023166, 24.705882352941178, 19.12350597609562], 'bp': 0.3924440825576447, 'sys_len': 526, 'ref_len': 1018} 6.792000000000001e-06\n",
      "1700 1.2027997970581055 0.002232142857142857 {'score': 9.460070036070388, 'counts': [166, 118, 90, 67], 'totals': [429, 421, 413, 405], 'precisions': [38.6946386946387, 28.028503562945367, 21.791767554479417, 16.54320987654321], 'bp': 0.3783150473009867, 'sys_len': 429, 'ref_len': 846} 6.392000000000001e-06\n",
      "1750 0.6639528274536133 0.006756756756756757 {'score': 11.28219029499677, 'counts': [235, 189, 159, 134], 'totals': [561, 553, 545, 537], 'precisions': [41.889483065953655, 34.177215189873415, 29.174311926605505, 24.953445065176908], 'bp': 0.3531020333600962, 'sys_len': 561, 'ref_len': 1145} 5.992e-06\n",
      "1800 1.0775151252746582 0.010964912280701754 {'score': 24.545363961668656, 'counts': [252, 185, 141, 107], 'totals': [445, 437, 429, 421], 'precisions': [56.62921348314607, 42.33409610983982, 32.86713286713287, 25.41567695961995], 'bp': 0.6524855457520217, 'sys_len': 445, 'ref_len': 635} 5.592000000000001e-06\n",
      "1850 0.804780125617981 0.0015432098765432098 {'score': 6.645815728454373, 'counts': [212, 160, 122, 93], 'totals': [600, 592, 584, 576], 'precisions': [35.333333333333336, 27.027027027027028, 20.89041095890411, 16.145833333333332], 'bp': 0.27896563782408473, 'sys_len': 600, 'ref_len': 1366} 5.1920000000000004e-06\n",
      "1900 0.7075636386871338 0.006944444444444444 {'score': 17.41158689229841, 'counts': [212, 171, 144, 124], 'totals': [432, 424, 416, 408], 'precisions': [49.074074074074076, 40.33018867924528, 34.61538461538461, 30.392156862745097], 'bp': 0.45836356826916247, 'sys_len': 432, 'ref_len': 769} 4.792000000000001e-06\n",
      "1950 0.8368552327156067 0.0021929824561403508 {'score': 8.739143266300326, 'counts': [186, 131, 95, 68], 'totals': [413, 405, 397, 389], 'precisions': [45.0363196125908, 32.34567901234568, 23.929471032745592, 17.480719794344473], 'bp': 0.3127886353708673, 'sys_len': 413, 'ref_len': 893} 4.3920000000000005e-06\n",
      "2000 0.9584644436836243 0.002777777777777778 {'score': 14.430251095756645, 'counts': [165, 130, 108, 88], 'totals': [355, 347, 339, 331], 'precisions': [46.478873239436616, 37.46397694524496, 31.858407079646017, 26.58610271903323], 'bp': 0.41408246223656014, 'sys_len': 355, 'ref_len': 668} 3.992e-06\n",
      "2050 0.6962317824363708 0.0 {'score': 7.36770153563903, 'counts': [186, 137, 109, 86], 'totals': [524, 516, 508, 500], 'precisions': [35.49618320610687, 26.550387596899224, 21.456692913385826, 17.2], 'bp': 0.30338638385452077, 'sys_len': 524, 'ref_len': 1149} 3.5920000000000005e-06\n",
      "2100 0.771067202091217 0.012295081967213115 {'score': 12.10464375249587, 'counts': [212, 152, 117, 89], 'totals': [487, 479, 471, 463], 'precisions': [43.53182751540041, 31.73277661795407, 24.840764331210192, 19.22246220302376], 'bp': 0.4247464681141713, 'sys_len': 487, 'ref_len': 904} 3.192e-06\n",
      "2150 0.5719201564788818 0.0 {'score': 5.69698294082286, 'counts': [195, 157, 130, 105], 'totals': [670, 662, 654, 646], 'precisions': [29.104477611940297, 23.716012084592144, 19.877675840978593, 16.25386996904025], 'bp': 0.2621585068568519, 'sys_len': 670, 'ref_len': 1567} 2.792e-06\n",
      "2200 0.8244491815567017 0.0037313432835820895 {'score': 9.597701250456165, 'counts': [196, 144, 114, 95], 'totals': [500, 492, 484, 476], 'precisions': [39.2, 29.26829268292683, 23.553719008264462, 19.95798319327731], 'bp': 0.35416229870357036, 'sys_len': 500, 'ref_len': 1019} 2.392e-06\n",
      "2250 0.8779654502868652 0.005319148936170213 {'score': 20.615544023744928, 'counts': [197, 148, 116, 91], 'totals': [362, 354, 346, 338], 'precisions': [54.41988950276243, 41.80790960451977, 33.52601156069364, 26.923076923076923], 'bp': 0.5445830589080478, 'sys_len': 362, 'ref_len': 582} 1.992e-06\n",
      "2300 0.9505125284194946 0.001488095238095238 {'score': 4.089062527705538, 'counts': [160, 114, 86, 67], 'totals': [626, 618, 610, 602], 'precisions': [25.559105431309906, 18.446601941747574, 14.098360655737705, 11.129568106312293], 'bp': 0.24793995226567583, 'sys_len': 626, 'ref_len': 1499} 1.5920000000000002e-06\n",
      "2350 1.0018764734268188 0.0024509803921568627 {'score': 7.216054898784825, 'counts': [281, 196, 145, 107], 'totals': [803, 795, 787, 779], 'precisions': [34.99377334993773, 24.654088050314467, 18.424396442185515, 13.735558408215661], 'bp': 0.33382587944334247, 'sys_len': 803, 'ref_len': 1684} 1.1920000000000002e-06\n",
      "2400 0.8622590899467468 0.002551020408163265 {'score': 9.48864330974091, 'counts': [156, 118, 94, 73], 'totals': [395, 387, 379, 371], 'precisions': [39.49367088607595, 30.49095607235142, 24.80211081794195, 19.67654986522911], 'bp': 0.3427047204344712, 'sys_len': 395, 'ref_len': 818} 7.920000000000001e-07\n",
      "2450 0.8322212100028992 0.00646551724137931 {'score': 12.492037786822925, 'counts': [202, 155, 125, 99], 'totals': [448, 440, 432, 424], 'precisions': [45.089285714285715, 35.22727272727273, 28.935185185185187, 23.349056603773583], 'bp': 0.38812471079490507, 'sys_len': 448, 'ref_len': 872} 3.92e-07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132b209a6980455a9b9b0540ba1a1911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7f24c8c12c4beaaec115f62bae4b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/423M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "\n",
    "#ËÆ≠ÁªÉ\n",
    "def train():\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0,\n",
    "                              num_training_steps=len(loader),\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "    \n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            out = out['logits'].argmax(dim=2)\n",
    "            correct = (data['decoder_input_ids'] == out).sum().item()\n",
    "            total = data['decoder_input_ids'].shape[1] * 8\n",
    "            accuracy = correct / total\n",
    "            del correct\n",
    "            del total\n",
    "\n",
    "            predictions = []\n",
    "            references = []\n",
    "            for j in range(8):\n",
    "                pred = tokenizer.decode(out[j])\n",
    "                label = tokenizer.decode(data['decoder_input_ids'][j])\n",
    "                predictions.append(pred)\n",
    "                references.append([label])\n",
    "\n",
    "            metric_out = metric.compute(predictions=predictions,\n",
    "                                        references=references)\n",
    "\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "            print(i, loss.item(), accuracy, metric_out, lr)\n",
    "\n",
    "    model.to('cpu')\n",
    "\n",
    "\n",
    "if push_to_hub:\n",
    "    train()\n",
    "    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed397281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5518d5b505345a48e7fc40103a971d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/105 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8ad099d6e04b9ab942f5010ad4bdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)\"pytorch_model.bin\";:   0%|          | 0.00/423M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Helsinki-NLP/opus-mt-en-ro were not used when initializing MarianModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing MarianModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MarianModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input_ids= ‚ñÅAfter the public emotion‚ñÅpasses,‚ñÅwe‚ñÅwill return to the‚ñÅreasons‚ñÅwe‚ñÅhave‚ñÅcreated‚ñÅthis‚ñÅspace, the‚ñÅfreedom of‚ñÅmovement that is not‚ñÅonly for‚ñÅpeople but‚ñÅalso for‚ñÅgoods.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= DupƒÉa ce emo emotia publica, ne vom intoarce la motivele pentru care am creat acesttiul,, libertatea libera de miscare care nu este numai pentru oameni, ci si pentru bunuri.</s> </s>,,,,,, - - - - - - - DupƒÉ DupƒÉ DupƒÉ DupƒÉ DupƒÉ DupƒÉ DupƒÉ DupƒÉ DupƒÉ DupƒÉ\n",
      "label= <pad> Dupa ce trece emotia publica, ne vom intoarce la motivele pentru care am creat spatiul acesta, aceasta libertate de miscare care nu e numai pentru oameni, ci »ôi pentru bunuri.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "2\n",
      "input_ids= Am I‚ñÅbad for the‚ñÅindustry?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Sunt fƒÉcut atitudine negativƒÉ asupra industriei?</s>. sunt sunt Fac Fac Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt Sunt\n",
      "label= <pad> Am o influen»õƒÉ proastƒÉ asupra industriei?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "4\n",
      "input_ids= ‚ñÅThat‚ñÅended‚ñÅany‚ñÅideas that Malmo‚ñÅhad of‚ñÅcoming‚ñÅback‚ñÅinto the game, and‚ñÅonly a superb stop by Wiland from‚ñÅpoint-blank‚ñÅrange to‚ñÅdeny David Luiz‚ñÅkept the final‚ñÅscore‚ñÅdown‚ñÅbefore‚ñÅsubstitute Ezequiel Lavezzi‚ñÅhad a‚ñÅgoal disallowed‚ñÅright‚ñÅat the‚ñÅdeath.</s>\n",
      "pred= Acest lucru a pus oriceele cƒÉ pe la Malmo de va reveniintra»ôlibbra meciul final doar o super superb al lui Wiland de la distan, a ultim Luiz a fost scorul final √Ænainte ca √Ænlocui- √Æn Ezequiel Lavzzi sƒÉ aibƒÉ se fieze scopul gol chiar momentulle</s>\n",
      "label= <pad> Acest gol a eliminat speran»õa celor de la Malmo cƒÉ vor reechilibra scorul »ôi doar un stop superb al lui Wiland de la distan»õƒÉ pentru respingerea David Luiz a men»õinut scorul final √Ænainte ca nou intratului Ezequiel Lavezzi sƒÉ i se anuleze un gol √Æn prelungiri.\n",
      "6\n",
      "input_ids= The BBC‚ñÅMusic‚ñÅAwards‚ñÅwhich‚ñÅstarted‚ñÅlast‚ñÅyear‚ñÅseem to be the Brits by‚ñÅanother name.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= PreBC Music Awards, care anul trecut, par a fie britanicits cu alt alt nume.</s>, B B B B B B B B B B B B B B B B B B B B B B B B B B B Pre Pre Pre Pre Pre Pre Pre Pre Pre\n",
      "label= <pad> BBC Music Awards, lansate anul trecut, par sƒÉ fie Brits sub un alt nume.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "8\n",
      "input_ids= You are a‚ñÅgreat‚ñÅpower‚ñÅonly‚ñÅif you‚ñÅhave‚ñÅsolutions.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Sunte sunt o, doar daca ai solu solu»õiitii.</s>, esteti- - - - - Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte Sunte\n",
      "label= <pad> Dar esti mare putere doar daca ai »ôi solutii.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "10\n",
      "input_ids= The‚ñÅcompany‚ñÅalso‚ñÅsaid‚ñÅit‚ñÅplans to‚ñÅhire‚ñÅabout 55,000‚ñÅseasonal‚ñÅworkers for the‚ñÅholidays.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "pred= Compania a declarat de asemenea cƒÉ inten sƒÉ angajeze aproximativ vacan de 55 000 de lucrƒÉtori sezonieri pentru sƒÉrbƒÉtori delor.</s>,ulul pentru Pentru Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania Compania\n",
      "label= <pad> Compania a declarat de asemenea cƒÉ inten»õioneazƒÉ sƒÉ angajeze √Æn jur de 55.000 de lucrƒÉtori sezonieri pentru perioada sƒÉrbƒÉtorilor.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "{'score': 8.71658710506789, 'counts': [2000, 1378, 1008, 737], 'totals': [5299, 5211, 5123, 5035], 'precisions': [37.74297037176826, 26.444060640951832, 19.675971110677338, 14.637537239324727], 'bp': 0.3764474607075469, 'sys_len': 5299, 'ref_len': 10476}\n"
     ]
    }
   ],
   "source": [
    "#Áõ¥Êé•‰ΩøÁî®ÊàëËÆ≠ÁªÉÂ•ΩÁöÑÊ®°Âûã\n",
    "model = Model.from_pretrained(repo_id)\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
